{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd64ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1396a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '..'\n",
    "mesh_file_dir = rootdir + \"/mesh_file\"\n",
    "text_file_dir = rootdir + \"/text\"\n",
    "\n",
    "classification_res = np.loadtxt('../classification_result.txt')\n",
    "classification_res = classification_res.astype('int')\n",
    "\n",
    "output_size = np.loadtxt(rootdir + \"/param/output_size.txt\")\n",
    "output_size = output_size.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool,global_max_pool\n",
    "\n",
    "class GCN_1(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN_1, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(9, hidden_channels)\n",
    "        self.conv2 = GCNConv(128, 256)\n",
    "        self.conv3 = GCNConv(256, 256)\n",
    "        self.conv4 = GCNConv(256, 256)\n",
    "        self.linear4 = Linear(128,256)   #\n",
    "        self.linear2 = Linear(256,128)\n",
    "        self.linear3 = Linear(128,128)\n",
    "        self.lin = Linear(128, output_size[classification_res - 1])\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        \n",
    "\n",
    "        x = global_max_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        x = x.relu()\n",
    "        x = self.linear3(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin(x)\n",
    "        x = x.squeeze()\n",
    "        return x\n",
    "\n",
    "class GCN_2(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN_2, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(12, hidden_channels)\n",
    "        self.conv2 = GCNConv(128, 256)\n",
    "        self.conv3 = GCNConv(256, 256)\n",
    "        self.conv4 = GCNConv(256, 256)\n",
    "        self.linear4 = Linear(128,256) #\n",
    "        self.linear2 = Linear(256,128)\n",
    "        self.linear3 = Linear(128,128)\n",
    "        self.lin = Linear(128, output_size[classification_res - 1])\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        \n",
    "\n",
    "        x = global_max_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = x.relu()\n",
    "        x = self.linear3(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin(x)\n",
    "        x = x.squeeze()\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "class GCN_3(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN_3, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(12, hidden_channels)  \n",
    "        self.conv2 = GCNConv(128, 256)\n",
    "        self.conv3 = GCNConv(256, 512)\n",
    "        self.conv4 = GCNConv(512, 512)\n",
    "        self.linear4 = Linear(128,256)  #\n",
    "        self.linear2 = Linear(512,1024)\n",
    "        self.linear3 = Linear(1024,512)\n",
    "        self.lin = Linear(512, output_size[classification_res - 1])\n",
    " \n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        \n",
    "\n",
    "        x = global_max_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = x.relu()\n",
    "        x = self.linear3(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin(x)\n",
    "        x = x.squeeze()\n",
    "        return x\n",
    "\n",
    "    \n",
    "if classification_res == 2:\n",
    "    model = GCN_1(hidden_channels=128)\n",
    "elif classification_res in [3,4,5,6,7]:\n",
    "    model = GCN_2(hidden_channels=128)\n",
    "elif classification_res in [1,8,9,10]:\n",
    "    model = GCN_3(hidden_channels=128)\n",
    "print(model)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe5018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "model_list = [\n",
    "    \"ring_800center_1920_12_e16c_warmup.ckpt\",\n",
    "    \"longgenes1_800center_2_nostandardization.ckpt\",\n",
    "    \"mount1_800center_1536_12_36c_warmup_new_scaled_v2.ckpt\",\n",
    "    \"mount2_800center_2112_12_30c_warmup.ckpt\",\n",
    "    \"ex1_800center_1760_12_e26c_warmup_v2.ckpt\",\n",
    "    \"cat4_800center_4096_12_26c.ckpt\",\n",
    "    \"cat5_800center_3024_12_30c.ckpt\",\n",
    "    \"cow_800center_2432_12_62c_warmup_v4.ckpt\",\n",
    "    \"fandisk_800center_2176_12_68c_warmup_v8.ckpt\",\n",
    "    \"rockerarm_800center_3552_12_126c_warmup_new_v3_7_126.ckpt\"\n",
    "]\n",
    "\n",
    "model.load_state_dict(torch.load(\"../model_parameter/\" + model_list[classification_res - 1])) \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41817109",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "x_input = dataset[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2147f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "feature = np.loadtxt(text_file_dir + '/testfeature.txt')\n",
    "edge = np.loadtxt(text_file_dir + '/testedge.txt')\n",
    "\n",
    "feature = torch.from_numpy(feature).to(torch.float32)[:,:]\n",
    "edge = torch.from_numpy(edge).to(torch.int64).transpose(0,1)\n",
    "\n",
    "meanfeat = torch.mean(feature[:,:9].reshape(-1,3,3),axis = 1).numpy()\n",
    "\n",
    "\n",
    "data1 = Data(x = feature[:,:9],edge_index = edge) if classification_res == 2 else Data(x = feature[:,:],edge_index = edge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96abc16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "test_name = \"test_data.pt\"\n",
    "\n",
    "\n",
    "class MyDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [test_name]\n",
    "\n",
    "    def download(self):\n",
    "        pass \n",
    "\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        data = data1\n",
    "        data_list.append(data)\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "if(classification_res == 2) and (os.path.exists('../data/processed/' + test_name)):\n",
    "    os.remove('../data/processed/' + test_name)\n",
    "dataset = MyDataset(root = '../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b103dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "res1 = model(dataset[0].x,dataset[0].edge_index,torch.from_numpy(np.zeros(dataset[0].x.shape[0])).to(torch.int64))\n",
    "print(res1)\n",
    "resres = res1.detach().numpy()\n",
    "r = resres.reshape(output_size[classification_res - 1] // 3,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a1fa28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "_cats = np.loadtxt(text_file_dir + '/test_multi_cats_merged.txt')\n",
    "_cats_centers = np.loadtxt(text_file_dir + '/test_centers.txt')\n",
    "_cats_centers_id = np.loadtxt(text_file_dir + '/test_centers_id.txt').astype('int')\n",
    "\n",
    "if classification_res == 1:\n",
    "    numofmapping = [1,1,\n",
    "                1,1,\n",
    "                1,1,\n",
    "                1,1,\n",
    "                4,\n",
    "                4]\n",
    "elif classification_res == 2:\n",
    "    numofmapping = [1,1,1,1,2,1,2,1,5,5]\n",
    "elif classification_res == 3:\n",
    "    numofmapping = [5,1,2,4,6,1,6,1,1,2,1,1,4,1]\n",
    "elif classification_res == 4:\n",
    "    numofmapping = [1,1,1,1,1,1,1,1,1,1,1,1,4,4,1,9]    \n",
    "elif classification_res == 5:\n",
    "    numofmapping = [1,2,1,1,2,1,1,2,1,1,2,1,1,4,1,4]\n",
    "elif classification_res == 6:\n",
    "    numofmapping = [1,1,1,2,1,3,1,3,1,2,4,5,1]    \n",
    "elif classification_res == 7:\n",
    "    numofmapping = [1,1,1,1,3,1,4,1,4,1,1,1,4,5,1]      \n",
    "elif classification_res == 8:\n",
    "    numofmapping = [1,7,1,1,8,1,1,1,8,1,1,1,8,1,1,10,1,1,1,1,1,5]       \n",
    "elif classification_res == 9:\n",
    "    numofmapping = [9,1,1,1,2,\n",
    "                    4,4,\n",
    "                    2,3,2,2,\n",
    "                    2,7,\n",
    "                    10,1,1,1,3,\n",
    "                    12]\n",
    "elif classification_res == 10:\n",
    "    numofmapping = [3,2,1,9,1,1,1,\n",
    "                   1,3,1,1,1,1,3,6,\n",
    "                   1,2,1,3,2,1,2,2,6,\n",
    "                   2,12,5,3,\n",
    "                   1,19,2,2,\n",
    "                   21,2,2]    \n",
    "_cats_mapping = [list(range(sum(numofmapping[:i]),sum(numofmapping[:i]) + numofmapping[i])) for i in range(len(numofmapping))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d04f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if classification_res == 2:\n",
    "    tmp = r[5].copy()\n",
    "    r[5] = r[6].copy()\n",
    "    r[6] = tmp.copy()\n",
    "\n",
    "    tmp = r[8].copy()\n",
    "    r[8] = r[9].copy()\n",
    "    r[9] = tmp.copy()\n",
    "elif classification_res == 3:\n",
    "    tmp0 = (r[2,2] + r[0,2]) / 2\n",
    "    tmp1 = (r[1,1] + r[3,1] + r[4,1]) / 3\n",
    "    tmp2 = (r[15,0] + r[22,0]) / 2\n",
    "    tmp3 = (r[16,0] + r[23,0]) / 2\n",
    "    tmp4 = (r[8,2] + r[10,2]) / 2\n",
    "\n",
    "    r[0,2] = tmp0\n",
    "    r[2,2] = tmp0\n",
    "    r[1,1] = tmp1\n",
    "    r[3,1] = tmp1\n",
    "    r[4,1] = tmp1\n",
    "    r[15,0] = tmp2\n",
    "    r[22,0] = tmp2\n",
    "    r[16,0] = tmp3\n",
    "    r[23,0] = tmp3\n",
    "    r[8,2] = tmp4\n",
    "    r[10,2] = tmp4\n",
    "elif classification_res == 4:\n",
    "    tmp0 = (r[22,1] + r[24,1] + r[26,1] + r[28,1]) / 4\n",
    "    tmp1 = (r[21,0] + r[23,0] + r[25,0] + r[27,0]) / 4\n",
    "    tmp2 = (r[13,1] + r[15,1] + r[17,1] + r[19,1]) / 4\n",
    "    tmp3 = (r[12,0] + r[14,0] + r[16,0] + r[18,0]) / 4\n",
    "\n",
    "    r[22,1] = tmp0\n",
    "    r[24,1] = tmp0\n",
    "    r[26,1] = tmp0\n",
    "    r[28,1] = tmp0\n",
    "\n",
    "    r[21,0] = tmp1\n",
    "    r[23,0] = tmp1\n",
    "    r[25,0] = tmp1\n",
    "    r[27,0] = tmp1\n",
    "\n",
    "    r[29,0] = tmp1\n",
    "    r[29,1] = tmp0\n",
    "\n",
    "    r[13,1] = tmp2\n",
    "    r[15,1] = tmp2\n",
    "    r[17,1] = tmp2\n",
    "    r[19,1] = tmp2\n",
    "\n",
    "    r[12,0] = tmp3\n",
    "    r[14,0] = tmp3\n",
    "    r[16,0] = tmp3\n",
    "    r[18,0] = tmp3\n",
    "elif classification_res == 6:\n",
    "    for k in range(2):\n",
    "        r[k * 3 : k * 3 + 3,2] = _cats_centers[:3,2]\n",
    "        r[k * 4 + 6 : k * 4 + 8,2] = _cats_centers[0,2]\n",
    "        r[k * 4 + 8,2] = _cats_centers[1,2]\n",
    "        r[k * 4 + 9,2] = _cats_centers[2,2]\n",
    "elif classification_res == 7:\n",
    "    mapping = [[0,1,2,3],[4,5,6,7],[8,9,10,11,12],[13,14,15,16,17],[18,19,20,21,22,23],[24,25,26,27,28,29]]\n",
    "    K_means_cat = np.loadtxt(text_file_dir + '/Kmeans_mean.txt')\n",
    "    mf = meanfeat[:,:3]\n",
    "    tmp_cat = [i for i,x in enumerate(K_means_cat) if x == 0]\n",
    "    epoch = 10\n",
    "    u = r[mapping[0],:]\n",
    "    for i in range(epoch):\n",
    "        p = u[np.newaxis,:]\n",
    "        p = p.repeat(len(tmp_cat),axis = 0)\n",
    "        res = np.sum((mf[tmp_cat].reshape(len(tmp_cat),1,3) - p)**2,axis = 2)\n",
    "        argres = np.argmin(res,axis = 1)\n",
    "        #\n",
    "        for i in range(4):\n",
    "            u[i] = np.mean(mf[np.array(tmp_cat)[(argres == i)]],axis = 0)\n",
    "    new_z = u\n",
    "    for k in range(2):\n",
    "        r[k*4:4*(k+1),2] = new_z[:,2]\n",
    "        r[8 + k * 5,2] = new_z[0,2]\n",
    "        r[8 + k * 5 + 1,2] = new_z[1,2]\n",
    "        r[8 + k * 5 + 2,2] = new_z[1,2]\n",
    "        r[8 + k * 5 + 3,2] = new_z[2,2]\n",
    "        r[8 + k * 5 + 4,2] = new_z[3,2]\n",
    "elif classification_res == 8:\n",
    "    key_values = _cats_centers[[18,17,20,19,0,5,3,2]]\n",
    "    r[[23,26,28,34,37,39,43,44,45,57],0] = key_values[0][0]\n",
    "    r[[21,24,27,32,35,38,49,50,51,61],0] = key_values[2][0]\n",
    "\n",
    "    mid_key_value_1 = (key_values[0][0] + key_values[2][0]) / 2\n",
    "\n",
    "    r[[22,25,33,36,46,47,48,58,59,60],0] = mid_key_value_1\n",
    "\n",
    "    r[42,0] = key_values[4][0] \n",
    "\n",
    "    r[[1,3,6,10,13,16,43,46,49,60],1] = key_values[0][1]\n",
    "    r[[2,5,7,12,15,17,45,48,51,58],1] = key_values[1][1]\n",
    "\n",
    "    mid_key_value_2 = (key_values[0][1] + key_values[1][1]) / 2\n",
    "\n",
    "    r[[4,11,14,42,44,47,50,57,59,61],1] = mid_key_value_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47253880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "s_cat = [[],[]]\n",
    "\n",
    "\n",
    "subcat = []\n",
    "cat = []\n",
    "accum_cat = 0\n",
    "count = 0\n",
    "for j in _cats_centers_id:\n",
    "    print(j)\n",
    "    tmp_cat = [i for i,x in enumerate(_cats) if x == j]\n",
    "    cat.append(tmp_cat)\n",
    "    p = r[_cats_mapping[count],:][np.newaxis,:]\n",
    "    p = p.repeat(len(cat[count]),axis = 0)\n",
    "    res = np.sum((meanfeat[cat[count]].reshape(len(cat[count]),1,3) - p)**2,axis = 2)\n",
    "    argres = np.argmin(res,axis = 1)\n",
    "    subcat.append(argres)\n",
    "    \n",
    "    for i in range(len(tmp_cat)):\n",
    "        s_cat[0].append(tmp_cat[i])\n",
    "    for i in range(len(argres)):\n",
    "        s_cat[1].append(argres[i] + accum_cat)\n",
    "    \n",
    "    print(\"accum_cat\",accum_cat)\n",
    "    accum_cat += len(_cats_mapping[count])\n",
    "    count += 1\n",
    "\n",
    "s_cat = np.array(s_cat).T\n",
    "u = s_cat[np.argsort(s_cat[:,0])][:,1]\n",
    "np.savetxt(text_file_dir + '/test_allfaces.txt',u)\n",
    "np.savetxt(text_file_dir + '/len_test.txt',np.array(accum_cat).reshape(1))\n",
    "\n",
    "edge = edge.numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c5bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "u = np.loadtxt(text_file_dir + '/test_allfaces.txt')\n",
    "alist = [2,6,10,14]\n",
    "new_edge = edge.reshape(int(edge.shape[0] / 3),-1)[:,[0,1,3,5]]\n",
    "adj_cat = u[(new_edge)].astype('int')\n",
    "t = u\n",
    "\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    adj_cat = u[(new_edge)].astype('int')\n",
    "    for i in range(len(adj_cat)):\n",
    "        if classification_res == 8:\n",
    "            check = (np.argmax(np.bincount(adj_cat[i][1:])))\n",
    "            if check != adj_cat[i][0]:\n",
    "                u[i] = check\n",
    "                adj_cat = u[(new_edge)].astype('int')\n",
    "                #print(\"cat8\",i,check)\n",
    "        cnt = 0\n",
    "        loc = 0\n",
    "        for j in range(1,4):\n",
    "            if adj_cat[i][0] != adj_cat[i][j]: \n",
    "                cnt += 1\n",
    "            elif adj_cat[i][0] == adj_cat[i][j]:\n",
    "                loc = new_edge[i][j]\n",
    "        if cnt == 3:\n",
    "            print(\"y\",i)\n",
    "            adj_cat[i][0] = np.argmax(np.bincount(adj_cat[i][1:]))\n",
    "        if (classification_res not in [8,9]) and (cnt == 2):\n",
    "            cnt2 = 0\n",
    "            for j in range(1,4):\n",
    "                if adj_cat[loc][0] != adj_cat[loc][j]:\n",
    "                    cnt2 += 1\n",
    "            if cnt2 == 2:\n",
    "                print(\"isolated_diamond\",i)\n",
    "                tmp = np.argmax(np.bincount(adj_cat[i][1:]))\n",
    "                adj_cat[i][0] = tmp\n",
    "                adj_cat[loc][0] = tmp\n",
    "        u = adj_cat[:,0]\n",
    "np.savetxt(text_file_dir + '/newnew_test_allfaces.txt',u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e400d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
